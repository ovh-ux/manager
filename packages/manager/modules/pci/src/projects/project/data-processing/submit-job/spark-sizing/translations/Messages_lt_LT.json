{
  "data_processing_submit_job_sizing_template_memory_label": "GB memory",
  "data_processing_submit_job_sizing_template_cores_label": "virtual cores",
  "data_processing_submit_job_sizing_description": "Your Spark job is managed by a master node (driver) distributing tasks to the computing nodes (executor). Select the number of cores and the quantity of memory allocated to your nodes, as well as the number of nodes you want.",
  "data_processing_submit_job_stepper_spark_driver_template_label": "Driver model",
  "data_processing_submit_job_stepper_spark_worker_template_label": "Executor model",
  "data_processing_submit_job_stepper_spark_worker_count_label": "Number of executors",
  "data_processing_submit_job_stepper_spark_worker_count_description": "Select the number of executors for your job",
  "data_processing_submit_job_stepper_spark_advanced": "Advanced configuration",
  "data_processing_submit_job_stepper_spark_standard": "Standard configuration",
  "data_processing_submit_job_stepper_spark_driver_cores_label": "Number of virtual cores for the driver",
  "data_processing_submit_job_stepper_spark_driver_memory_label": "Driver memory",
  "data_processing_submit_job_stepper_spark_driver_memory_overhead_label": "Driver memory overhead",
  "data_processing_submit_job_stepper_spark_worker_cores_label": "Number of virtual cores for the executor",
  "data_processing_submit_job_stepper_spark_worker_memory_label": "Executor memory",
  "data_processing_submit_job_stepper_spark_worker_memory_description": "Select the quantity of memory per executor",
  "data_processing_submit_job_stepper_spark_worker_memory_overhead_label": "Executor memory overhead",
  "data_processing_submit_job_stepper_spark_estimated_price": "Estimated price: "
}
