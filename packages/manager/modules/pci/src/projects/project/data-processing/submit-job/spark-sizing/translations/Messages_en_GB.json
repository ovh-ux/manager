{
  "data_processing_submit_job_sizing_template_memory_label": "GB memory",
  "data_processing_submit_job_sizing_template_cores_label": "vCores",
  "data_processing_submit_job_sizing_description": "Your Spark job is ran by a driver node which distributes tasks to executors. Define cores and memory allocated to your nodes and the number of workers you want to run in parallel",
  "data_processing_submit_job_stepper_spark_driver_template_label": "Driver template",
  "data_processing_submit_job_stepper_spark_worker_template_label": "Executor template",
  "data_processing_submit_job_stepper_spark_worker_count_label": "Executor count",
  "data_processing_submit_job_stepper_spark_worker_count_description": "Select the number of executors for your job",
  "data_processing_submit_job_stepper_spark_advanced": "Advanced configuration",
  "data_processing_submit_job_stepper_spark_standard": "Standard configuration",
  "data_processing_submit_job_stepper_spark_driver_cores_label": "Driver vCores",
  "data_processing_submit_job_stepper_spark_driver_memory_label": "Driver memory",
  "data_processing_submit_job_stepper_spark_driver_memory_overhead_label": "Driver memory overhead",
  "data_processing_submit_job_stepper_spark_worker_cores_label": "Executors vCores",
  "data_processing_submit_job_stepper_spark_worker_memory_label": "Executor memory",
  "data_processing_submit_job_stepper_spark_worker_memory_description": "Select the amount of memory per Spark executor",
  "data_processing_submit_job_stepper_spark_worker_memory_overhead_label": "Executor memory overhead",
  "data_processing_submit_job_stepper_spark_estimated_price": "Estimated price: "
}
