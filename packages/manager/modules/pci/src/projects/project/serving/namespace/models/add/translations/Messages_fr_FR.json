{
  "pci_projects_project_serving_namespace_models_add_error": "Une erreur est survenue durant la création du modèle: {{ message }}",
  "pci_projects_project_serving_namespace_models_add_success": "Votre modèle est en cours de création",
  "pci_projects_project_serving_namespace_models_add": "Déployer un modèle",
  "pci_projects_project_serving_namespace_models_add_type": "Type de modèle",
  "pci_projects_project_serving_namespace_models_add_type_preset-image": "Modèle prédéfini",
  "pci_projects_project_serving_namespace_models_add_type_preset-image_popover": "Sélectionnez parmi la liste des modèles prédéfinis",
  "pci_projects_project_serving_namespace_models_add_type_build-image": "Modèle personnalisé",
  "pci_projects_project_serving_namespace_models_add_type_build-image_popover": "Déployer votre modèle personnalisé",
  "pci_projects_project_serving_namespace_models_add_name": "Nom",
  "pci_projects_project_serving_namespace_models_add_name_help": "Le nom du modèle doit commencer par une lettre minuscule (a-z), peut comporter des chiffres et le signe de ponctuation \"-\" et doit finir par un caractère alphanumérique. (ex. 'mon-name',  or 'abc-123')",
  "pci_projects_project_serving_namespace_models_add_framework": "Framework",
  "pci_projects_project_serving_namespace_models_add_framework_how_to": "Comment téléverser votre modèle",
  "pci_projects_project_serving_namespace_models_add_backend": "Backend",
  "pci_projects_project_serving_namespace_models_add_backend_description": "Serveur HTTP qui va utiliser votre modèle pour faire des prédictions",
  "pci_projects_project_serving_namespace_models_add_advanced": "Avancé",
  "pci_projects_project_serving_namespace_models_add_recommended": "Recommandé",
  "pci_projects_project_serving_namespace_models_add_model": "Modèle",
  "pci_projects_project_serving_namespace_models_add_instances": "Configuration des instances",
  "pci_projects_project_serving_namespace_models_add_autoscaling": "Auto Scaling",
  "pci_projects_project_serving_namespace_models_add_storage_path_info_file": "Sélectionnez le chemin vers le fichier de votre modèle dans l'Object Storage. Votre fichier doit avoir l'extension : h5 / pmml or onnx",
  "pci_projects_project_serving_namespace_models_add_storage_path_info_folder": "Sélectionnez le chemin vers le répertoire contenant votre modèle dans l'Object Storage",
  "pci_projects_project_serving_namespace_models_add_storage_path_no_path": "Votre Object Storage est vide, vous pouvez ajouter vos modèles ici",
  "pci_projects_project_serving_namespace_models_common_add": "Déployer",
  "pci_projects_project_serving_namespace_models_common_cancel": "Annuler",
  "pci_projects_project_serving_namespace_models_id": "ID",
  "pci_projects_project_serving_namespace_models_storage_path": "Répertoire Object Storage",
  "pci_projects_project_serving_namespace_models_storage_scale_min": "Instances minimum",
  "pci_projects_project_serving_namespace_models_storage_scale_max": "Instances maximum",
  "pci_projects_project_serving_namespace_models_add_model_preset_info": "Plus d'informations",
  "pci_projects_project_serving_namespace_models_add_folder_mode": "Dossier",
  "pci_projects_project_serving_namespace_models_add_file_mode": "Fichier",
  "pci_projects_project_serving_namespace_models_add_custom_info": "Retrouvez la liste des formats compatibles dans notre documentation",
  "pci_projects_project_serving_namespace_models_scale_advanced_configuration": "Configuration avancée",
  "pci_projects_project_serving_namespace_models_scale_advanced_configuration_memory": "% Utilisation Mémoire",
  "pci_projects_project_serving_namespace_models_scale_advanced_configuration_cpu": "% Utilisation CPU",
  "pci_projects_project_serving_namespace_models_add_price_unit": "heure"
}
