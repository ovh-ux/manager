{
  "pci_projects_project_serving_namespace_models_add_error": "Se ha producido un error al crear el modelo: {{ message }}",
  "pci_projects_project_serving_namespace_models_add_success": "Creando el modelo...",
  "pci_projects_project_serving_namespace_models_add": "Desplegar un modelo",
  "pci_projects_project_serving_namespace_models_add_type": "Tipo de modelo",
  "pci_projects_project_serving_namespace_models_add_type_preset-image": "Modelo predefinido",
  "pci_projects_project_serving_namespace_models_add_type_preset-image_popover": "Seleccione un modelo en la lista de modelos predefinidos",
  "pci_projects_project_serving_namespace_models_add_type_build-image": "Modelo personalizado",
  "pci_projects_project_serving_namespace_models_add_type_build-image_popover": "Desplegar un modelo personalizado",
  "pci_projects_project_serving_namespace_models_add_name": "Nombre",
  "pci_projects_project_serving_namespace_models_add_name_help": "El nombre del modelo debe comenzar por una letra minúscula (a-z), puede incluir cifras y guiones («-»), y debe terminar por un carácter alfanumérico (p. ej.: «mi-nombre» o «abc-123»).",
  "pci_projects_project_serving_namespace_models_add_model": "Modelo",
  "pci_projects_project_serving_namespace_models_add_instances": "Configuración de las instancias",
  "pci_projects_project_serving_namespace_models_add_autoscaling": "Autoscaling",
  "pci_projects_project_serving_namespace_models_add_storage_path_info_file": "Seleccione la ruta hacia el archivo de su modelo en el Object Storage. Su archivo debe tener la extensión: h5 / pmml o onnx.",
  "pci_projects_project_serving_namespace_models_add_storage_path_info_folder": "Seleccione la ruta hacia el directorio que contiene su modelo en el Object Storage.",
  "pci_projects_project_serving_namespace_models_add_storage_path_no_path": "Su Object Storage está vacío. Puede añadir sus modelos aquí.",
  "pci_projects_project_serving_namespace_models_common_add": "Desplegar",
  "pci_projects_project_serving_namespace_models_common_cancel": "Cancelar",
  "pci_projects_project_serving_namespace_models_id": "ID",
  "pci_projects_project_serving_namespace_models_storage_path": "Directorio Object Storage",
  "pci_projects_project_serving_namespace_models_storage_scale_min": "Número mínimo de instancias",
  "pci_projects_project_serving_namespace_models_storage_scale_max": "Número máximo de instancias",
  "pci_projects_project_serving_namespace_models_add_model_preset_info": "Más información",
  "pci_projects_project_serving_namespace_models_add_folder_mode": "Carpeta",
  "pci_projects_project_serving_namespace_models_add_file_mode": "Archivo",
  "pci_projects_project_serving_namespace_models_add_custom_info": "Consulte la lista de formatos compatibles en nuestra documentación.",
  "pci_projects_project_serving_namespace_models_scale_advanced_configuration": "Configuración avanzada",
  "pci_projects_project_serving_namespace_models_scale_advanced_configuration_memory": "% de uso de memoria",
  "pci_projects_project_serving_namespace_models_scale_advanced_configuration_cpu": "% de uso de CPU",
  "pci_projects_project_serving_namespace_models_add_price_unit": "hora",
  "pci_projects_project_serving_namespace_models_add_framework": "Framework",
  "pci_projects_project_serving_namespace_models_add_framework_how_to": "Cómo cargar el modelo",
  "pci_projects_project_serving_namespace_models_add_backend": "Backend",
  "pci_projects_project_serving_namespace_models_add_backend_description": "Servidor HTTP que va a utilizar su modelo para realizar predicciones",
  "pci_projects_project_serving_namespace_models_add_advanced": "Avanzado",
  "pci_projects_project_serving_namespace_models_add_recommended": "Recomendado"
}
